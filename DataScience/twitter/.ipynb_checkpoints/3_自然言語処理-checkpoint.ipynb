{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‰å‡¦ç†\n",
    "from data_cleaning import CleanTW\n",
    "tw = CleanTW().run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡</th>\n",
       "      <th>ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x</th>\n",
       "      <th>æ™‚é–“</th>\n",
       "      <th>ã„ã„ã­</th>\n",
       "      <th>ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ</th>\n",
       "      <th>ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³</th>\n",
       "      <th>ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ</th>\n",
       "      <th>ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡</th>\n",
       "      <th>è¿”ä¿¡</th>\n",
       "      <th>ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯</th>\n",
       "      <th>URLã‚¯ãƒªãƒƒã‚¯æ•°</th>\n",
       "      <th>ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚¯ãƒªãƒƒã‚¯</th>\n",
       "      <th>è©³ç´°ã‚¯ãƒªãƒƒã‚¯</th>\n",
       "      <th>ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ã„ã‚‹</th>\n",
       "      <th>ãƒ¡ãƒ‡ã‚£ã‚¢ã®å†ç”Ÿæ•°</th>\n",
       "      <th>ãƒ¡ãƒ‡ã‚£ã‚¢ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ•°</th>\n",
       "      <th>æ–‡å­—æ•°</th>\n",
       "      <th>media_exist</th>\n",
       "      <th>reply_flg</th>\n",
       "      <th>YMD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@teatime3fairy ã“ã¡ã‚‰ã“ãå®œã—ããŠé¡˜ã„ã—ã¾ã™ğŸ˜†</td>\n",
       "      <td>ã“ã¡ã‚‰ã“ãå®œã—ããŠé¡˜ã„ã—ã¾ã™ğŸ˜†</td>\n",
       "      <td>2021-03-30 14:34:00+00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20210330</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã­ã‚€ã­ã‚€ã‚€ã‚€ğŸ¥± https://t.co/Ggro68dOXM</td>\n",
       "      <td>ã­ã‚€ã­ã‚€ã‚€ã‚€ğŸ¥±</td>\n",
       "      <td>2021-03-30 07:57:00+00:00</td>\n",
       "      <td>216.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2654.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.124717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20210330</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡          ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x  \\\n",
       "0   @teatime3fairy ã“ã¡ã‚‰ã“ãå®œã—ããŠé¡˜ã„ã—ã¾ã™ğŸ˜†   ã“ã¡ã‚‰ã“ãå®œã—ããŠé¡˜ã„ã—ã¾ã™ğŸ˜†   \n",
       "1  ã­ã‚€ã­ã‚€ã‚€ã‚€ğŸ¥± https://t.co/Ggro68dOXM          ã­ã‚€ã­ã‚€ã‚€ã‚€ğŸ¥±    \n",
       "\n",
       "                         æ™‚é–“    ã„ã„ã­  ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ  ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³  ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ  ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡   è¿”ä¿¡  \\\n",
       "0 2021-03-30 14:34:00+00:00    1.0    0.0      14.0       1.0   0.071429  0.0   \n",
       "1 2021-03-30 07:57:00+00:00  216.0    3.0    2654.0     331.0   0.124717  0.0   \n",
       "\n",
       "   ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯  URLã‚¯ãƒªãƒƒã‚¯æ•°  ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚¯ãƒªãƒƒã‚¯  è©³ç´°ã‚¯ãƒªãƒƒã‚¯  ãƒ•ã‚©ãƒ­ãƒ¼ã—ã¦ã„ã‚‹  ãƒ¡ãƒ‡ã‚£ã‚¢ã®å†ç”Ÿæ•°  \\\n",
       "0             0.0       0.0         0.0     0.0         0         0   \n",
       "1            44.0       3.0         0.0    29.0         0       463   \n",
       "\n",
       "   ãƒ¡ãƒ‡ã‚£ã‚¢ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ•°  æ–‡å­—æ•° media_exist reply_flg       YMD  YEAR  MONTH  DAY  \\\n",
       "0               0   16           0         1  20210330  2021      3   30   \n",
       "1              36    8           1         0  20210330  2021      3   30   \n",
       "\n",
       "   TIME  WEEKDAY  WEEK  \n",
       "0    14        1    13  \n",
       "1     7        1    13  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å½¢æ…‹ç´ è§£æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['çŠ¬\\tåè©,ä¸€èˆ¬,*,*,*,*,çŠ¬,ã‚¤ãƒŒ,ã‚¤ãƒŒ',\n",
       " 'ãªã—\\tå½¢å®¹è©,è‡ªç«‹,*,*,å½¢å®¹è©ãƒ»ã‚¢ã‚¦ã‚ªæ®µ,æ–‡èªåŸºæœ¬å½¢,ãªã„,ãƒŠã‚·,ãƒŠã‚·',\n",
       " 'ã§\\tåŠ©å‹•è©,*,*,*,ç‰¹æ®Šãƒ»ãƒ€,é€£ç”¨å½¢,ã ,ãƒ‡,ãƒ‡',\n",
       " 'äºº\\tåè©,ä¸€èˆ¬,*,*,*,*,äºº,ãƒ’ãƒˆ,ãƒ’ãƒˆ',\n",
       " 'ã¯\\tåŠ©è©,ä¿‚åŠ©è©,*,*,*,*,ã¯,ãƒ,ãƒ¯',\n",
       " 'å¹¸ã›\\tåè©,å½¢å®¹å‹•è©èªå¹¹,*,*,*,*,å¹¸ã›,ã‚·ã‚¢ãƒ¯ã‚»,ã‚·ã‚¢ãƒ¯ã‚»',\n",
       " 'ã«\\tåŠ©è©,å‰¯è©åŒ–,*,*,*,*,ã«,ãƒ‹,ãƒ‹',\n",
       " 'ãªã‚Œ\\tå‹•è©,è‡ªç«‹,*,*,ä¸€æ®µ,æœªç„¶å½¢,ãªã‚Œã‚‹,ãƒŠãƒ¬,ãƒŠãƒ¬',\n",
       " 'ãªã„\\tåŠ©å‹•è©,*,*,*,ç‰¹æ®Šãƒ»ãƒŠã‚¤,åŸºæœ¬å½¢,ãªã„,ãƒŠã‚¤,ãƒŠã‚¤',\n",
       " 'EOS']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "text = 'çŠ¬ãªã—ã§äººã¯å¹¸ã›ã«ãªã‚Œãªã„'\n",
    "words = tagger.parse(text).splitlines()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆ\n",
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "text = 'çŠ¬ğŸ¶ãªã—ã§ã€äººã¯å¹¸ã›ğŸ’“ã«ãªã‚Œãªã„ã€‚No one can be happy without a dog'\n",
    "words = tagger.parse(text).splitlines()\n",
    "parts = ['åè©','å‹•è©','å½¢å®¹è©','å½¢å®¹å‹•è©','æ¥ç¶šè©','é€£ä½“è©']\n",
    "words_arr = []\n",
    "for i in words:\n",
    "  if i == 'EOS' or i == '':continue\n",
    "  word_tmp = i.split()[0]\n",
    "  part = i.split()[1].split(',')[0]\n",
    "  if not (part in parts):continue\n",
    "  words_arr.append({part:word_tmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'åè©': 'çŠ¬'},\n",
       " {'å½¢å®¹è©': 'ãªã—'},\n",
       " {'åè©': 'äºº'},\n",
       " {'åè©': 'å¹¸ã›'},\n",
       " {'å‹•è©': 'ãªã‚Œ'},\n",
       " {'åè©': 'No'},\n",
       " {'åè©': 'one'},\n",
       " {'åè©': 'can'},\n",
       " {'åè©': 'be'},\n",
       " {'åè©': 'happy'},\n",
       " {'åè©': 'without'},\n",
       " {'åè©': 'a'},\n",
       " {'åè©': 'dog'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã„ã„ã­ãŒå¤šã„åè©ã¨ãã®å‡ºç¾å›æ•°ã‚’èª¿ã¹ã‚‹\n",
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "all_words = []\n",
    "goods = []\n",
    "parts = ['åè©']\n",
    "for n in range(len(tw)):\n",
    "  text = tw.iloc[n]['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x']\n",
    "  words = tagger.parse(text).splitlines()\n",
    "  words_arr = []\n",
    "  for i in words:\n",
    "    if i == 'EOS' or i == '':continue\n",
    "    word_tmp = i.split()[0]\n",
    "    part = i.split()[1].split(',')[0]\n",
    "    if not (part in parts):continue\n",
    "    words_arr.append(word_tmp)\n",
    "    goods.append(tw.iloc[n]['ã„ã„ã­'])\n",
    "  all_words.extend(words_arr)\n",
    "  \n",
    "df = pd.DataFrame({\n",
    "  'word':all_words,\n",
    "  'ã„ã„ã­':goods,\n",
    "  'å›æ•°':len(all_words) * [1]\n",
    "})\n",
    "\n",
    "df_good = df.groupby('word')['ã„ã„ã­'].mean()\n",
    "df_count = df.groupby('word')['å›æ•°'].sum()\n",
    "df_a = pd.concat([df_good,df_count],axis=1)\n",
    "\n",
    "df_rank = df_a.loc[df_a['å›æ•°']>3].sort_values('ã„ã„ã­', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ã„ã„ã­</th>\n",
       "      <th>å›æ•°</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ã‚«ã‚­</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ãƒ€ãƒƒãƒ•ã‚£</td>\n",
       "      <td>545.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>æ­³</td>\n",
       "      <td>545.428571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æ•</td>\n",
       "      <td>469.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ãŠæ°—ã«å…¥ã‚Š</td>\n",
       "      <td>448.900000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ã“ã‚Œ</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ä»Š</td>\n",
       "      <td>390.428571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ã“ã“</td>\n",
       "      <td>316.166667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>å›</td>\n",
       "      <td>311.142857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>å‘¼å¸</td>\n",
       "      <td>301.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word         ã„ã„ã­  å›æ•°\n",
       "0     ã‚«ã‚­  555.000000   4\n",
       "1   ãƒ€ãƒƒãƒ•ã‚£  545.800000   5\n",
       "2      æ­³  545.428571   7\n",
       "3      æ•  469.600000   5\n",
       "4  ãŠæ°—ã«å…¥ã‚Š  448.900000  10\n",
       "5     ã“ã‚Œ  391.000000   9\n",
       "6      ä»Š  390.428571   7\n",
       "7     ã“ã“  316.166667   6\n",
       "8      å›  311.142857   7\n",
       "9     å‘¼å¸  301.800000   5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã„ã„ã­ãŒå¤šã„å‹•è©ã¨ãã®å‡ºç¾å›æ•°ã‚’èª¿ã¹ã‚‹\n",
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "all_words = []\n",
    "goods = []\n",
    "parts = ['å‹•è©']\n",
    "for n in range(len(tw)):\n",
    "  text = tw.iloc[n]['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x']\n",
    "  words = tagger.parse(text).splitlines()\n",
    "  words_arr = []\n",
    "  for i in words:\n",
    "    if i == 'EOS' or i == '':continue\n",
    "    word_tmp = i.split()[0]\n",
    "    part = i.split()[1].split(',')[0]\n",
    "    if not (part in parts):continue\n",
    "    words_arr.append(word_tmp)\n",
    "    goods.append(tw.iloc[n]['ã„ã„ã­'])\n",
    "  all_words.extend(words_arr)\n",
    "  \n",
    "df = pd.DataFrame({\n",
    "  'word':all_words,\n",
    "  'ã„ã„ã­':goods,\n",
    "  'å›æ•°':len(all_words) * [1]\n",
    "})\n",
    "\n",
    "df_good = df.groupby('word')['ã„ã„ã­'].mean()\n",
    "df_count = df.groupby('word')['å›æ•°'].sum()\n",
    "df_a = pd.concat([df_good,df_count],axis=1)\n",
    "\n",
    "df_rank = df_a.loc[df_a['å›æ•°']>3].sort_values('ã„ã„ã­', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ã„ã„ã­</th>\n",
       "      <th>å›æ•°</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æ§‹ã£</td>\n",
       "      <td>477.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>è€ƒãˆ</td>\n",
       "      <td>407.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>è¡Œã“</td>\n",
       "      <td>398.857143</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ã—ã¾ã„</td>\n",
       "      <td>390.600000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ãŠã‚Š</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ã§ã</td>\n",
       "      <td>330.833333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ãã‚‹</td>\n",
       "      <td>322.571429</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ç–²ã‚Œ</td>\n",
       "      <td>289.800000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>é–‹ã‘</td>\n",
       "      <td>289.666667</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>è¡Œã</td>\n",
       "      <td>283.625000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word         ã„ã„ã­  å›æ•°\n",
       "0   æ§‹ã£  477.500000   4\n",
       "1   è€ƒãˆ  407.500000   4\n",
       "2   è¡Œã“  398.857143   7\n",
       "3  ã—ã¾ã„  390.600000   5\n",
       "4   ãŠã‚Š  369.000000   4\n",
       "5   ã§ã  330.833333   6\n",
       "6   ãã‚‹  322.571429   7\n",
       "7   ç–²ã‚Œ  289.800000   5\n",
       "8   é–‹ã‘  289.666667   6\n",
       "9   è¡Œã  283.625000   8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒªãƒ„ã‚¤ãƒ¼ãƒˆæ•°ãŒå¤šã„åè©ã¨ãã®å‡ºç¾å›æ•°ã‚’èª¿ã¹ã‚‹\n",
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "all_words = []\n",
    "goods = []\n",
    "parts = ['åè©']\n",
    "for n in range(len(tw)):\n",
    "  text = tw.iloc[n]['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x']\n",
    "  words = tagger.parse(text).splitlines()\n",
    "  words_arr = []\n",
    "  for i in words:\n",
    "    if i == 'EOS' or i == '':continue\n",
    "    word_tmp = i.split()[0]\n",
    "    part = i.split()[1].split(',')[0]\n",
    "    if not (part in parts):continue\n",
    "    words_arr.append(word_tmp)\n",
    "    goods.append(tw.iloc[n]['ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ'])\n",
    "  all_words.extend(words_arr)\n",
    "  \n",
    "df = pd.DataFrame({\n",
    "  'word':all_words,\n",
    "  'ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ':goods,\n",
    "  'å›æ•°':len(all_words) * [1]\n",
    "})\n",
    "\n",
    "df_good = df.groupby('word')['ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ'].mean()\n",
    "df_count = df.groupby('word')['å›æ•°'].sum()\n",
    "df_a = pd.concat([df_good,df_count],axis=1)\n",
    "\n",
    "df_rank = df_a.loc[df_a['å›æ•°']>3].sort_values('ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ</th>\n",
       "      <th>å›æ•°</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ã‚«ã‚­</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ãƒ€ãƒƒãƒ•ã‚£</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>æ­³</td>\n",
       "      <td>22.714286</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>æ„Ÿ</td>\n",
       "      <td>15.400000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ãŠæ°—ã«å…¥ã‚Š</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ä»Š</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ç”¨</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>æ•</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ã“ã‚Œ</td>\n",
       "      <td>10.111111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ã‚„ã¤</td>\n",
       "      <td>9.909091</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word      ãƒªãƒ„ã‚¤ãƒ¼ãƒˆ  å›æ•°\n",
       "0     ã‚«ã‚­  25.000000   4\n",
       "1   ãƒ€ãƒƒãƒ•ã‚£  23.400000   5\n",
       "2      æ­³  22.714286   7\n",
       "3      æ„Ÿ  15.400000   5\n",
       "4  ãŠæ°—ã«å…¥ã‚Š  14.200000  10\n",
       "5      ä»Š  14.000000   7\n",
       "6      ç”¨  13.500000   6\n",
       "7      æ•  12.000000   5\n",
       "8     ã“ã‚Œ  10.111111   9\n",
       "9     ã‚„ã¤   9.909091  11"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯æ•°ãŒå¤šã„åè©ã¨ãã®å‡ºç¾å›æ•°ã‚’èª¿ã¹ã‚‹\n",
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "all_words = []\n",
    "goods = []\n",
    "parts = ['åè©']\n",
    "for n in range(len(tw)):\n",
    "  text = tw.iloc[n]['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x']\n",
    "  words = tagger.parse(text).splitlines()\n",
    "  words_arr = []\n",
    "  for i in words:\n",
    "    if i == 'EOS' or i == '':continue\n",
    "    word_tmp = i.split()[0]\n",
    "    part = i.split()[1].split(',')[0]\n",
    "    if not (part in parts):continue\n",
    "    words_arr.append(word_tmp)\n",
    "    goods.append(tw.iloc[n]['ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯'])\n",
    "  all_words.extend(words_arr)\n",
    "  \n",
    "df = pd.DataFrame({\n",
    "  'word':all_words,\n",
    "  'ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯':goods,\n",
    "  'å›æ•°':len(all_words) * [1]\n",
    "})\n",
    "\n",
    "df_good = df.groupby('word')['ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯'].mean()\n",
    "df_count = df.groupby('word')['å›æ•°'].sum()\n",
    "df_a = pd.concat([df_good,df_count],axis=1)\n",
    "\n",
    "df_rank = df_a.loc[df_a['å›æ•°']>3].sort_values('ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯', ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯</th>\n",
       "      <th>å›æ•°</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æ­³</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å˜”å</td>\n",
       "      <td>213.750000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>è‚ºç‚</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>å›</td>\n",
       "      <td>155.428571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>æ™‚é–“</td>\n",
       "      <td>143.285714</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ã“ã‚Œ</td>\n",
       "      <td>135.777778</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ã¨ã“ã‚</td>\n",
       "      <td>127.857143</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ã‚«ã‚­</td>\n",
       "      <td>118.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ä»Š</td>\n",
       "      <td>103.428571</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>æœ€é«˜</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word  ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯  å›æ•°\n",
       "0    æ­³      227.000000   7\n",
       "1   å˜”å      213.750000   4\n",
       "2   è‚ºç‚      180.000000  14\n",
       "3    å›      155.428571   7\n",
       "4   æ™‚é–“      143.285714   7\n",
       "5   ã“ã‚Œ      135.777778   9\n",
       "6  ã¨ã“ã‚      127.857143   7\n",
       "7   ã‚«ã‚­      118.500000   4\n",
       "8    ä»Š      103.428571   7\n",
       "9   æœ€é«˜       98.500000   4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é¡ä¼¼ãƒ„ã‚¤ãƒ¼ãƒˆæ¤œç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = MeCab.Tagger('-d /usr/local/lib/mecab/dic/ipadic')\n",
    "all_words_df = pd.DataFrame()\n",
    "parts = ['åè©','å‹•è©','å½¢å®¹è©']\n",
    "goods = []\n",
    "for n in range(len(tw)):\n",
    "  text = tw.iloc[n]['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x']\n",
    "  words = tagger.parse(text).splitlines()\n",
    "  words_df = pd.DataFrame()\n",
    "  for i in words:\n",
    "    if i == 'EOS' or i == '':continue\n",
    "    word_tmp = i.split()[0]\n",
    "    part = i.split()[1].split(',')[0]\n",
    "    if not (part in parts):continue\n",
    "    words_df[word_tmp] = [1]\n",
    "    goods.append(tw.iloc[n]['ã„ã„ã­'])\n",
    "  all_words_df = pd.concat([all_words_df, words_df],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_df = all_words_df.fillna(0)\n",
    "all_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tw.loc[tw['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³'] == tw['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³'].max()].index)\n",
    "print(tw.loc[tw['ã„ã„ã­'] == tw['ã„ã„ã­'].max()].index)\n",
    "print(tw.loc[tw['ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯'] == tw['ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚¯ãƒªãƒƒã‚¯'].max()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tw['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x'].iloc[230])\n",
    "tar_text = all_words_df.iloc[230]\n",
    "tar_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã§æ¤œç´¢\n",
    "\n",
    "cos_sim = []\n",
    "for i in range(len(all_words_df)):\n",
    "  cos_text = all_words_df.iloc[i]\n",
    "  cos = np.dot(tar_text, cos_text) / np.linalg.norm(tar_text) * np.linalg.norm(cos_text)\n",
    "  cos_sim.append(cos)\n",
    "all_words_df['cos_sim'] = cos_sim\n",
    "all_words_df = all_words_df.sort_values('cos_sim', ascending=False)\n",
    "all_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_df.head(11).index[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in all_words_df.head(11).index[1:]:\n",
    "  print(\"**********\",idx, \"**********\")\n",
    "  print(tw.iloc[idx]['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.matplotlib_fname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "font_path=\"~/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf/ipaexg.ttf\"\n",
    "splitted = ' '.join([x.split('\\t')[0] for x in all_words_df.columns])\n",
    "wordc = WordCloud(font_path=font_path,background_color='white',width=800, height=600).generate(splitted)\n",
    "\n",
    "plt.imshow(wordc)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF\n",
    "<div style='text-align:left; display: block;'>\n",
    "    $$bow(w,d)=[æ–‡æ›¸då†…ã§å˜èªwãŒå‡ºç¾ã™ã‚‹å›æ•°]$$\n",
    "    $$tf(w,d)=bow(w,d)/[æ–‡æ›¸då˜èªæ•°]$$\n",
    "    $$idf(w)=[å…¨æ–‡æ›¸æ•°N]/[å˜èªwãŒå«ã¾ã‚Œã‚‹æ–‡æ›¸æ•°]$$\n",
    "    $$tfidf(w,d)=tf(w,d)*idf(w,d)$$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFã¯å˜èªã®å‡ºç¾é »åº¦ï¼ˆTerm Frequencyï¼‰ã€IDFã¯é€†æ–‡æ›¸é »åº¦ï¼ˆInverse Document Frequencyï¼‰\n",
    "\n",
    "# TFã¯ã€å„æ–‡ç« ã«ãŠã‘ã‚‹å„å˜èªã®å‡ºç¾å›æ•°ã§ã‚ã‚‹ä¸Šè¿°ã®Bag-of-Wordsã‚’æ­£è¦åŒ–ã—ã¦é »åº¦ã«å¤‰ãˆãŸã‚‚ã®\n",
    "\n",
    "# IDFã¯ã‚ã‚‹å˜èªãŒã©ã‚Œã ã‘æƒ…å ±ã‚’ã‚‚ãŸã‚‰ã™ã‹ã‚’è¡¨ã™é‡ã§ã€å¤šãã®æ–‡æ›¸ã«å‡ºç¾ã™ã‚‹å˜èªã®å½±éŸ¿ã¯å¼±ããªã‚Šã€ã”ãä¸€éƒ¨ã®æ–‡æ›¸ã«å‡ºç¾ã™ã‚‹å˜èªã®å½±éŸ¿ãŒå¼·ããªã‚‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤ºã™ã‚‹ã¨ãã‚«ãƒ©ãƒ ã‚’çœç•¥ã—ãªã„\n",
    "pd.set_option('display.max_columns', None)\n",
    "# æµ®å‹•å°æ•°ç‚¹ã‚’è¡¨ç¤ºã™ã‚‹ã¨ãã¯å°æ•°ç‚¹ä»¥ä¸‹ 2 æ¡ã§æƒãˆã‚‹\n",
    "pd.options.display.float_format = '{:0.2f}'.format\n",
    "\n",
    "# å–ã‚Šæ‰±ã†ã‚³ãƒ¼ãƒ‘ã‚¹\n",
    "corpus = tw['ãƒ„ã‚¤ãƒ¼ãƒˆæœ¬æ–‡_x'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦‹ã‚„ã™ã•ã®ãŸã‚ã«è¡¨ç¤ºã™ã‚‹ã¨ãã¯ pandas ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã™ã‚‹\n",
    "df_count = pd.DataFrame(data=all_words_df,\n",
    "                  columns=all_words_df.columns)\n",
    "print('--- BoW (Bag of Words) ---')\n",
    "print(df_count.shape)\n",
    "display(df_count.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print('--- IDF (Inverse Document Frequency) ---')\n",
    "df_idf = pd.DataFrame(data=[tfidf_vectorizer.idf_],\n",
    "                  columns=tfidf_vectorizer.get_feature_names())\n",
    "print(df_idf.shape)\n",
    "display(df_idf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- TF-IDF ---')\n",
    "df_tfidf = pd.DataFrame(data=X_tfidf.toarray(),\n",
    "                  columns=tfidf_vectorizer.get_feature_names())\n",
    "print(df_tfidf.shape)\n",
    "display(df_tfidf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
